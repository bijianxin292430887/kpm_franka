defaults:
  - agent: idm_latent_policy

method: ''
agent_name: idm_latent_policy
dynamics_model_name: ''
log_dir: logs/spoon/

seed: 42
action_data_ratio: 2

hydra:
  run:
    dir: ${log_dir}/runs/${agent_name}
  sweep:
    dir: ${log_dir}/sweeps/${agent_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}

# insert wandb here
wandb:
  entity: bijianxin292430887
  project: d3il

group: spoon_${agent_name}


backbone: 'lstm'
# Action Decoder Network
hidden_dims: [256]
# FSQ
fsq_levels: [6,6,6,6]
fsq_latent_dim: 4
# AE/VQ-VAE
ae_latent_dim: 4
codebook_size: 256
#VAE
vae_latent_dim: 4
kl_factor: 0.0001
#Koopman
kpm_latent_dim: 256
target_k: -1

#Cotrain
action_loss_factor: 0.01

# Training
train_batch_size: 256
val_batch_size: 256
num_workers: 4
device: 'cuda'
epoch: 500
eval_every_n_epochs: 5
decoder_eval_every_n_epochs: 5
scale_data: False
# use eval dataset to normalize data
#scale_set: True
# Environment
obs_dim: 7
action_dim: 7
max_len_data: 512
window_size: 1

obs_mask_dim: [0]
## Dataset
trainset:
valset:
